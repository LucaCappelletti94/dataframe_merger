{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from scipy.stats import ks_2samp, mannwhitneyu\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from typing import List, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _and(*args):\n",
    "    return np.all(args, axis=0)\n",
    "\n",
    "def _or(*args):\n",
    "    return np.any(args, axis=0)\n",
    "\n",
    "def drop_nan(df):\n",
    "    return [df[c][~np.isclose(df[c].values, 0)].dropna() for c in df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_type_argsort(matrix: np.matrix, df: pd.DataFrame) -> np.matrix:\n",
    "    \"\"\"Return given `matrix` sorted using given `df` DataFrame types.\"\"\"\n",
    "    return matrix[np.argsort(\n",
    "        list(zip(*sorted(zip(df.dtypes, range(len(df.dtypes))))))[1]), :]\n",
    "\n",
    "\n",
    "def double_argsort(floats: np.matrix,\n",
    "                   strings: np.matrix,\n",
    "                   df1: pd.DataFrame,\n",
    "                   df2: pd.DataFrame,\n",
    "                   fill=0) -> np.matrix:\n",
    "    \"\"\"Return combined matrix sorted in both axis using given dataframes types.\"\"\"\n",
    "    ground = np.full((df1.shape[1], df2.shape[1]), float(fill))\n",
    "    if np.all(floats.shape):\n",
    "        ground[:floats.shape[0], :floats.shape[1]] = floats\n",
    "    if np.all(strings.shape):\n",
    "        ground[-strings.shape[0]:, -strings.shape[1]:] = strings\n",
    "    return matrix_type_argsort(matrix_type_argsort(ground, df1).T, df2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_tfidf_distance(df1: pd.DataFrame, df2: pd.DataFrame,\n",
    "                        data_tfidf) -> np.matrix:\n",
    "    \"\"\"Return cosine distance of dataframes columns mean tfidf vectorization.\n",
    "        df1:pd.DataFrame, first string only dataframe.\n",
    "        df2:pd.DataFrame, second string only dataframe.\n",
    "    \"\"\"\n",
    "    if not df1.shape[1] or not df2.shape[1]:\n",
    "        return np.ones((df1.shape[1], df2.shape[1]))\n",
    "    a = np.array([\n",
    "    ]).squeeze(axis=1)\n",
    "    b = np.array([\n",
    "        np.mean(data_tfidf.transform(c), axis=0) for c in drop_nan(df2)\n",
    "    ]).squeeze(axis=1)\n",
    "    return cosine_distances(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_data_distances(df1: pd.DataFrame, df2: pd.DataFrame, data_tfidf):\n",
    "    return double_argsort(\n",
    "        np.array([]),\n",
    "        data_tfidf_distance(\n",
    "            df1.select_dtypes(include='object'),\n",
    "            df2.select_dtypes(include='object'),\n",
    "            data_tfidf) < 0.75,\n",
    "        df1,\n",
    "        df2,\n",
    "        fill=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_test(A: pd.DataFrame, B: pd.DataFrame, test:Callable, minimum=100):\n",
    "    df1 = drop_nan(A.select_dtypes(include='float64'))\n",
    "    df2 = drop_nan(B.select_dtypes(include='float64'))\n",
    "    return double_argsort(\n",
    "        np.array([[test(a, b)[1] if a.size > minimum and b.size > minimum else 0 for b in df2] for a in df1]),\n",
    "        np.array([]), A, B, 0)\n",
    "\n",
    "def pairwise_ks(A: pd.DataFrame, B: pd.DataFrame):\n",
    "    return pairwise_test(A, B, ks_2samp)\n",
    "\n",
    "def pairwise_mw(A: pd.DataFrame, B: pd.DataFrame):\n",
    "    return pairwise_test(A, B, mannwhitneyu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columns_tfidf_cosine(A, B, column_tfidf):\n",
    "    return cosine_distances(\n",
    "            column_tfidf.transform(A.columns),\n",
    "            column_tfidf.transform(B.columns)) < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def units_mask(A: np.ndarray, B: np.ndarray):\n",
    "    sep = \" | \"\n",
    "    unit_A, unit_B = [\n",
    "        np.array(\n",
    "            [None if len(c.split(sep)) == 1 else c.split(sep)[1] for c in v])\n",
    "        for v in [A, B]\n",
    "    ]\n",
    "    return unit_A[:, None] == unit_B\n",
    "\n",
    "\n",
    "def sub_incidence_matrix(column_tfidf, data_tfidf, A: pd.DataFrame,\n",
    "                         B: pd.DataFrame):\n",
    "    mw = pairwise_mw(A, B)\n",
    "    ks = pairwise_ks(A, B)\n",
    "    #_, mk_p = typewise_mk(A, B, data_tfidf)\n",
    "    \n",
    "    # means = string_data_distances(A, B, data_tfidf)\n",
    "    # tfidf = columns_tfidf_cosine(A, B, column_tfidf)\n",
    "    # tfidf<0.75\n",
    "    # print(np.nanmin(ksp), np.nanmax(ksp), np.nanmean(ksp), np.nanvar(ksp))\n",
    "    return _and(mw>0.1, ks>0.1)#_and(means, tfidf, ks_p>1e-3, mk_p>1e-3, units_mask(A.columns, B.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incidence_matrix(column_corpus:List[str], data_corpus:List[str], dataframes:List[pd.DataFrame]):\n",
    "    n = sum([df.shape[1] for df in dataframes])\n",
    "    column_tfidf = TfidfVectorizer()\n",
    "    column_tfidf.fit(column_corpus)\n",
    "    data_tfidf = TfidfVectorizer()\n",
    "    data_tfidf.fit(data_corpus)\n",
    "    ground = np.zeros((n, n))\n",
    "    old = np.array([0, 0])\n",
    "    offset = 0\n",
    "    for i, df1 in tqdm(enumerate(dataframes), total=len(dataframes)):\n",
    "        old[1] = offset\n",
    "        for j, df2 in enumerate(dataframes[i:], i):\n",
    "            if i == j:\n",
    "                matrix = np.eye(df1.shape[1])\n",
    "            else:\n",
    "                matrix = sub_incidence_matrix(column_tfidf, data_tfidf, df1, df2)\n",
    "            x = slice(old[0], old[0] + df1.shape[1])\n",
    "            y = slice(old[1], old[1] + df2.shape[1])\n",
    "            ground[x, y] = matrix\n",
    "            ground[y, x] = matrix.T\n",
    "            old[1] += df2.shape[1]\n",
    "        offset += df1.shape[1]\n",
    "        old[0] += df1.shape[1]\n",
    "\n",
    "    return ground.astype(bool)#np.matrix(ground)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching(dataframes: List[pd.DataFrame]):\n",
    "    corpus = np.array([c for df in dataframes for c in df.columns])\n",
    "    data_corpus = np.concatenate([df.select_dtypes(include='object').values.flatten() for df in dataframes])\n",
    "    data_corpus = data_corpus[~pd.isna(data_corpus)]\n",
    "    return incidence_matrix(corpus, data_corpus, dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../sanitized_csv/\"\n",
    "csvs = [\n",
    "    csv\n",
    "    for path, dirs, csvs in os.walk(path)\n",
    "    for csv in csvs\n",
    "]\n",
    "dataframes = [\n",
    "    pd.read_csv(\"{path}/{csv}\".format(path=path, csv=csv), index_col=[\"name\"])\n",
    "    for csv in csvs\n",
    "]\n",
    "columns = np.array([c for df in dataframes for c in df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be6cad5d40f4bcf87cb4f897ee88b3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "M = matching(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.matrix(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acqua | g' 'acqua | g']\n",
      "['calorie | kcal' 'calorie | kcal' 'energia, ric con fibra | kcal'\n",
      " 'energia, ricalcolata | kcal']\n",
      "['fibra alimentare | g' 'fibra alimentare totale | g']\n",
      "['proteine totali | g' 'proteine totali | g']\n",
      "['proteine animali | g' 'proteine : | %' 'proteine | g']\n",
      "['proteine vegetali | g' 'sugars' 'c18:1 | g' 'monoinsaturi totali | g'\n",
      " 'saturi totali | g']\n",
      "['glucidi solubili | g' 'zuccheri | g']\n",
      "['lipidi animali | g' 'grassi | g' 'grassi | g' 'lipidi animali | g']\n",
      "['lipidi saturi totali | g' 'acidi grassi monoinsaturi totali | g'\n",
      " 'acidi grassi saturi totali | g']\n",
      "['acido oleico | g' 'acido oleico | g']\n",
      "['acido linoleico | g' 'acido linoleico | g' 'c18:0 | g']\n",
      "['altri polinsaturi | g' 'c16:1 | g']\n",
      "['polinsaturi totali | g' 'c18:2 | g' 'c16:0 | g']\n",
      "['colesterolo | g' 'colesterolo | g' 'colesterolo | g']\n",
      "['sodio | g' 'sodium']\n",
      "['potassio | g' 'potassio | g' 'potassio | g']\n",
      "['fosforo | g' 'c20:1 | g' 'c20:4 | g' 'fosforo | g' 'c20:4 | g']\n",
      "['zinco | g' 'zinc']\n",
      "['tiamina (vitamina b1) | g' 'vitamina b1, tiamina | g']\n",
      "['riboflavina | g' 'riboflavina | g' 'vitamina b2, riboflavina | g'\n",
      " 'riboflavina | g']\n",
      "['niacina (vitamina pp) | g' 'niacina | g']\n",
      "['vitamina e | g' 'vitamina e | g']\n",
      "['alpha-tocoferolo (vitamina e) | g' 'vitamina e (ate) | g']\n",
      "['energy kcal' 'energia | kcal']\n",
      "['protein' 'proteine | g']\n",
      "['fatty acids, monounsaturated' 'saccarosio (mse) | g'\n",
      " 'zuccheri solubili | g']\n",
      "['fatty acids, saturated' 'proteine vegetali | g']\n",
      "['vitamin b2' 'tiamina | g']\n",
      "['vitamin b6' 'tiamina | g']\n",
      "['calcium' 'calcio | g']\n",
      "['zuccheri | g' 'lipidi totali | g']\n",
      "['acqua | g' 'acqua | g']\n",
      "['c14:0 | g' 'acido decosaesaenoico (dha) | g' 'sodio | g' 'c16:1 | g']\n",
      "['c16:0 | g' 'lattosio (mse) | g']\n",
      "['c18:0 | g' 'acidi grassi polinsaturi totali | g' 'acido stearico | g'\n",
      " 'c18:2 | g']\n",
      "['c18:3 | g' 'acido miristoleico | g' 'c14:0 | g' 'c18:3 | g']\n",
      "['carboidrati disponibili | g' 'carboidrati disponibili | g']\n",
      "['ferro | g' 'ferro | g']\n",
      "['fosforo | g' 'cistina | g' 'fosforo | g']\n",
      "['parte edibile | %' 'parte edibile | %']\n",
      "['sodio | g' 'sodio | g']\n",
      "['zuccheri solubili | g' 'fibre alimentari | g']\n",
      "['acido aspartico | g' 'acido aspartico | g']\n",
      "['prolina | g' 'prolina | g']\n",
      "['vitamina b3 | g' 'niacina | g']\n"
     ]
    }
   ],
   "source": [
    "M0 = np.copy(m)\n",
    "for i, row in enumerate(M0):\n",
    "    if np.sum(row) > 1:\n",
    "        rows = np.where(row)\n",
    "        M0[rows] = 0 \n",
    "        M0[:,rows] = 0 \n",
    "        print(columns[rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
