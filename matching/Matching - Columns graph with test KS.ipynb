{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_distances\n",
    "from pyscipopt import Model, quicksum\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.stats import ks_2samp\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from typing import List, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_matrix_sum(A, B):\n",
    "    return np.nansum(\n",
    "        [A.reshape(A.shape[0], 1, A.shape[1]),\n",
    "         B.reshape(1, *B.shape)], axis=0)\n",
    "\n",
    "\n",
    "def pairwise_vector_sum(A, B):\n",
    "    Ar = A.reshape(-1, 1)\n",
    "    Br = B.reshape(1, B.size)\n",
    "    if A.size==1:\n",
    "        return np.nansum([Ar, Br.T], axis=0).T \n",
    "    return np.nansum([Ar, Br], axis=0)\n",
    "\n",
    "def _and(*args):\n",
    "    return np.all(args, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_type_argsort(matrix: np.matrix, df: pd.DataFrame) -> np.matrix:\n",
    "    \"\"\"Return given `matrix` sorted using given `df` DataFrame types.\"\"\"\n",
    "    return matrix[np.argsort(list(zip(*sorted(zip(df.dtypes, range(len(df.dtypes))))))[1]),:]\n",
    "\n",
    "\n",
    "def double_argsort(floats: np.matrix, strings: np.matrix, df1: pd.DataFrame,\n",
    "                   df2: pd.DataFrame, fill=0) -> np.matrix:\n",
    "    \"\"\"Return combined matrix sorted in both axis using given dataframes types.\"\"\"\n",
    "    ground = np.full((df1.shape[1], df2.shape[1]), float(fill))\n",
    "    if np.all(floats.shape):\n",
    "        ground[:floats.shape[0], :floats.shape[1]] = floats\n",
    "    if np.all(strings.shape):\n",
    "        ground[-strings.shape[0]:, -strings.shape[1]:] = strings\n",
    "    return matrix_type_argsort(matrix_type_argsort(ground, df1).T, df2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mean_differences(A: np.matrix, B: np.matrix) -> np.matrix:\n",
    "    \"\"\"Return weighted mean differences of given matrices.\"\"\"\n",
    "    if not A.shape[1] or not A.shape[1]:\n",
    "        return np.zeros((A.shape[1], B.shape[1]))\n",
    "    X, Y = np.nanmean(A.values, axis=0), np.nanmean(B.values, axis=0)\n",
    "    N, M = np.sum(pd.notna(A.values), axis=0), np.sum(pd.notna(B.values), axis=0)\n",
    "    result = np.abs((pairwise_vector_sum(X, -Y) * pairwise_vector_sum(N, -M)) /\n",
    "                  (pairwise_vector_sum(X, Y) + pairwise_vector_sum(N, M)))\n",
    "    return result/np.max(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_values_mean_tfidf_distance(df1: pd.DataFrame,\n",
    "                                      df2: pd.DataFrame, data_tfidf) -> np.matrix:\n",
    "    \"\"\"Return cosine distance of dataframes columns mean tfidf vectorization.\n",
    "        df1:pd.DataFrame, first string only dataframe.\n",
    "        df2:pd.DataFrame, second string only dataframe.\n",
    "    \"\"\"\n",
    "    if not df1.shape[1] or not df2.shape[1]:\n",
    "        return np.zeros((df1.shape[1], df2.shape[1]))\n",
    "    a = np.array([np.mean(data_tfidf.transform(c), axis=0) for c in drop_nan(df1)]).squeeze(axis=1)\n",
    "    b = np.array([np.mean(data_tfidf.transform(c), axis=0) for c in drop_nan(df2)]).squeeze(axis=1)\n",
    "    return cosine_distances(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_variations(df1: pd.DataFrame, df2: pd.DataFrame, data_tfidf):\n",
    "    return double_argsort(\n",
    "        weighted_mean_differences(\n",
    "            df1.select_dtypes(include='float64'),\n",
    "            df2.select_dtypes(include='float64')),\n",
    "        column_values_mean_tfidf_distance(\n",
    "            df1.select_dtypes(include='object'),\n",
    "            df2.select_dtypes(include='object'),\n",
    "            data_tfidf), df1, df2, fill=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_ks(A: List[np.ndarray], B: List[np.ndarray]) -> np.matrix:\n",
    "    \"\"\"Return weighted mean differences of given matrices.\"\"\"\n",
    "    min_size = 100\n",
    "    if len(A) and len(B):\n",
    "        try:\n",
    "            return np.moveaxis(\n",
    "                np.array([[\n",
    "                    ks_2samp(a, b)\n",
    "                    if a.size > min_size and b.size > min_size else (0, 0)\n",
    "                    for b in B\n",
    "                ] for a in A]), [0,1,2], [1, 2, 0])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return np.full((len(A), len(B)), np.nan), np.full((len(A), len(B)), np.nan)\n",
    "\n",
    "\n",
    "def drop_nan(df):\n",
    "    return [df[c].iloc[df[c].nonzero()].dropna() for c in df]\n",
    "\n",
    "\n",
    "def typewise_ks(A: pd.DataFrame, B: pd.DataFrame, tfidf_data) -> np.matrix:\n",
    "    \"\"\"Return weighted mean differences of given matrices.\"\"\"\n",
    "    string_A = [\n",
    "        tfidf_data.transform(c)\n",
    "        for c in drop_nan(A.select_dtypes(include='object'))\n",
    "    ]\n",
    "    string_B = [\n",
    "        tfidf_data.transform(c)\n",
    "        for c in drop_nan(B.select_dtypes(include='object'))\n",
    "    ]\n",
    "    float_A = drop_nan(A.select_dtypes(include='float64'))\n",
    "    float_B = drop_nan(B.select_dtypes(include='float64'))\n",
    "    floats_s, floats_p = pairwise_ks(float_A, float_B)\n",
    "    strings_s, strings_p = pairwise_ks(string_A, string_B)\n",
    "    return double_argsort(floats_s, strings_s, A, B, 1), double_argsort(\n",
    "        floats_p, strings_p, A, B, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_minima(matrix):\n",
    "    return _and(\n",
    "        matrix == np.min(matrix, axis=1).reshape(-1, 1), matrix == np.min(\n",
    "            matrix, axis=0), ~np.isclose(matrix, np.nanmax(matrix)))\n",
    "\n",
    "\n",
    "def cross_maxima(matrix):\n",
    "    return _and(\n",
    "        matrix == np.max(matrix, axis=1).reshape(-1, 1), matrix == np.max(\n",
    "            matrix, axis=0), ~np.isclose(matrix, np.nanmin(matrix)))\n",
    "\n",
    "\n",
    "def units_mask(A: np.ndarray, B: np.ndarray):\n",
    "    sep = \" | \"\n",
    "    unit_A, unit_B = [\n",
    "        np.array(\n",
    "            [None if len(c.split(sep)) == 1 else c.split(sep)[1] for c in v])\n",
    "        for v in [A, B]\n",
    "    ]\n",
    "    return unit_A[:, None] == unit_B\n",
    "\n",
    "\n",
    "def sub_incidence_matrix(column_tfidf, data_tfidf, A: pd.DataFrame,\n",
    "                         B: pd.DataFrame):\n",
    "    s, p = typewise_ks(A, B, data_tfidf)\n",
    "    tfidf = cross_minima(\n",
    "        cosine_distances(\n",
    "            column_tfidf.transform(A.columns),\n",
    "            column_tfidf.transform(B.columns)))\n",
    "    means = cross_minima(mean_variations(A, B, data_tfidf))\n",
    "    return _and(np.sum([means, tfidf, p>1e-3], axis=0)>1, units_mask(A.columns, B.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incidence_matrix(column_corpus:List[str], data_corpus:List[str], dataframes:List[pd.DataFrame]):\n",
    "    n = sum([df.shape[1] for df in dataframes])\n",
    "    column_tfidf = TfidfVectorizer()\n",
    "    column_tfidf.fit(column_corpus)\n",
    "    data_tfidf = TfidfVectorizer()\n",
    "    data_tfidf.fit(data_corpus)\n",
    "    ground = np.zeros((n, n))\n",
    "    old = np.array([0, 0])\n",
    "    offset = 0\n",
    "    for i, df1 in tqdm(enumerate(dataframes), total=len(dataframes)):\n",
    "        old[1] = offset\n",
    "        for j, df2 in enumerate(dataframes[i:], i):\n",
    "            if i == j:\n",
    "                matrix = np.eye(df1.shape[1])\n",
    "            else:\n",
    "                matrix = sub_incidence_matrix(column_tfidf, data_tfidf, df1, df2)\n",
    "            x = slice(old[0], old[0] + df1.shape[1])\n",
    "            y = slice(old[1], old[1] + df2.shape[1])\n",
    "            ground[x, y] = matrix\n",
    "            ground[y, x] = matrix.T\n",
    "            old[1] += df2.shape[1]\n",
    "        offset += df1.shape[1]\n",
    "        old[0] += df1.shape[1]\n",
    "\n",
    "    return ground.astype(bool)#np.matrix(ground)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching(dataframes: List[pd.DataFrame]):\n",
    "    corpus = np.array([c for df in dataframes for c in df.columns])\n",
    "    data_corpus = np.concatenate([df.select_dtypes(include='object').values.flatten() for df in dataframes])\n",
    "    data_corpus = data_corpus[~pd.isna(data_corpus)]\n",
    "    return incidence_matrix(corpus, data_corpus, dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../sanitized_csv/\"\n",
    "csvs = [\n",
    "    csv\n",
    "    for path, dirs, csvs in os.walk(path)\n",
    "    for csv in csvs if \"svizz\" not in csv\n",
    "]\n",
    "dataframes = [\n",
    "    pd.read_csv(\"{path}/{csv}\".format(path=path, csv=csv), index_col=[\"name\"])\n",
    "    for csv in csvs\n",
    "]\n",
    "columns = np.array([c for df in dataframes for c in df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24d90a7c4cf3466885142b653fbc1dd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "axis -1 is out of bounds for array of dimension 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:31: RuntimeWarning: invalid value encountered in greater\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "axis -1 is out of bounds for array of dimension 0\n",
      "axis -1 is out of bounds for array of dimension 0\n",
      "axis -1 is out of bounds for array of dimension 0\n",
      "axis -1 is out of bounds for array of dimension 0\n",
      "axis -1 is out of bounds for array of dimension 0\n",
      "axis -1 is out of bounds for array of dimension 0\n",
      "axis -1 is out of bounds for array of dimension 0\n",
      "axis -1 is out of bounds for array of dimension 0\n",
      "axis -1 is out of bounds for array of dimension 0\n",
      "axis -1 is out of bounds for array of dimension 0\n",
      "axis -1 is out of bounds for array of dimension 0\n",
      "axis -1 is out of bounds for array of dimension 0\n",
      "axis -1 is out of bounds for array of dimension 0\n",
      "axis -1 is out of bounds for array of dimension 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "M = matching(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acqua | g' 'acqua | g' 'acqua | g' 'acqua | g' 'acqua | g']\n",
      "['calorie | kcal' 'calorie | kcal' 'calorie | kcal'\n",
      " 'energia, ric con fibra | kcal' 'energia, ricalcolata | kcal'\n",
      " 'valore calorico | kcal' 'energia | kcal']\n",
      "['fibra alimentare | g' 'fibra alimentare | g'\n",
      " 'fibra alimentare totale | g']\n",
      "['proteine totali | g' 'proteine totali | g' 'proteine | g']\n",
      "['proteine animali | g' 'proteine animali | g']\n",
      "['proteine vegetali | g' 'proteine vegetali | g']\n",
      "['glucidi disponibili | g' 'carboidrati disponibili (mse) | g'\n",
      " 'carboidrati disponibili | g']\n",
      "['glucidi solubili | g' 'carboidrati solubili (mse) | g'\n",
      " 'zuccheri solubili | g']\n",
      "['lipidi totali | g' 'carboidrati disponibili | g' 'lipidi totali | g'\n",
      " 'lipidi | g']\n",
      "['lipidi animali | g' 'lipidi animali | g']\n",
      "['lipidi vegetali | g' 'lipidi vegetali | g']\n",
      "['lipidi saturi totali | g' 'acido oleico | g']\n",
      "['acido oleico | g' 'acidi grassi saturi totali | g']\n",
      "['monoinsaturi totali | g' 'acidi grassi monoinsaturi totali | g'\n",
      " 'grassi monoinsaturi | g']\n",
      "['acido linoleico | g' 'acido linoleico | g']\n",
      "['polinsaturi totali | g' 'polinsaturi totali | g'\n",
      " 'acidi grassi polinsaturi totali | g' 'grassi polinsaturi | g']\n",
      "['colesterolo | g' 'colesterolo | g' 'colesterolo | g' 'colesterolo | g'\n",
      " 'colesterolo | g']\n",
      "['ferro | g' 'ferro | g' 'ferro | g' 'ferro | g' 'ferro | g']\n",
      "['calcio | g' 'calcio | g' 'calcio | g']\n",
      "['sodio | g' 'sodio | g' 'sodio | g' 'sodio | g']\n",
      "['potassio | g' 'potassio | g' 'potassio | g' 'potassio | g'\n",
      " 'potassio | g']\n",
      "['fosforo | g' 'fosforo | g' 'fosforo | g']\n",
      "['zinco | g' 'zinco | g']\n",
      "['tiamina (vitamina b1) | g' 'vitamina b1, tiamina | g' 'tiamina | g']\n",
      "['riboflavina | g' 'riboflavina | g' 'tiamina | g'\n",
      " 'vitamina b2, riboflavina | g' 'riboflavina | g']\n",
      "['niacina (vitamina pp) | g' 'niacina | g' 'niacina | g']\n",
      "['vitamina c | g' 'vitamina c | g' 'vitamina c | g' 'vitamina c | g']\n",
      "['vitamina d | g' 'fillochinone (vitamina k) | g' 'vitamina d | g']\n",
      "['vitamina e | g' 'vitamina e (ate) | g' 'vitamina e | g']\n",
      "['category' 'category' 'category' 'category']\n",
      "['vitamina e, aggiunta | g' 'vitamina k | g']\n",
      "['acidi grassi saturi | g' 'zuccheri | g']\n",
      "['grassi | g' 'grassi | g']\n",
      "['c12:0 | g' 'c12:0 | g']\n",
      "['c14:0 | g' 'c14:0 | g']\n",
      "['c16:0 | g' 'c16:0 | g']\n",
      "['c16:1 | g' 'c16:1 | g']\n",
      "['c18:0 | g' 'c18:0 | g' 'c18:2 | g']\n",
      "['c18:1 | g' 'c18:1 | g']\n",
      "['c18:3 | g' 'c18:3 | g']\n",
      "['c20:1 | g' 'acido decosaesaenoico (dha) | g' 'c20:4 | g']\n",
      "['c20:4 | g' 'acido arachidonico | g']\n",
      "['c20:5 | g' 'c20:5 | g']\n",
      "['c22:1 | g' 'c22:1 | g']\n",
      "['c22:6 | g' 'c22:6 | g']\n",
      "['calcio | g' 'calcio | g']\n",
      "['fosforo | g' 'fosforo | g']\n",
      "['niacina | g' 'vitamina b3 | g']\n",
      "['parte edibile | %' 'parte edibile | %']\n",
      "['proteine | g' 'proteine | g']\n",
      "['acido aspartico | g' 'acido aspartico | g']\n",
      "['acido glutammico | g' 'acido glutamico | g']\n",
      "['alanina | g' 'alanina | g']\n",
      "['arginina | g' 'arginina | g']\n",
      "['cistina | g' 'cistina | g']\n",
      "['fenilalanina | g' 'fenilalanina | g']\n",
      "['glicina | g' 'glicina | g' 'isoleucina | g']\n",
      "['istidina | g' 'istidina | g']\n",
      "['leucina | g' 'leucina | g']\n",
      "['lisina | g' 'lisina | g']\n",
      "['metionina | g' 'metionina | g']\n",
      "['prolina | g' 'prolina | g']\n",
      "['serina | g' 'serina | g']\n",
      "['tirosina | g' 'tirosina | g']\n",
      "['treonina | g' 'treonina | g']\n",
      "['triptofano | g' 'triptofano | g']\n",
      "['valina | g' 'valina | g']\n"
     ]
    }
   ],
   "source": [
    "M0 = np.copy(M)\n",
    "for i, row in enumerate(M0):\n",
    "    if np.sum(row) > 1:\n",
    "        rows = np.where(row)\n",
    "        M0[rows] = 0 \n",
    "        M0[:,rows] = 0 \n",
    "        print(columns[rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
