{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_distances\n",
    "from pyscipopt import Model, quicksum\n",
    "from scipy.sparse import csr_matrix\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from typing import List, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vitamins_heuristic(name:str)->str:\n",
    "    \"\"\"Return given `name` with applied vitamin heuristic.\n",
    "        name:str, the name to which apply the heuristic.\n",
    "    \"\"\"\n",
    "    return re.sub(\"(vitamina?) ([a-z\\d]+)\", r\"\\1_\\2\", name)\n",
    "\n",
    "def fats_heuristic(name:str)->str:\n",
    "    \"\"\"Return given `name` with applied fats heuristic.\n",
    "        name:str, the name to which apply the heuristic.\n",
    "    \"\"\"\n",
    "    return name.replace(\":\", \"_\")\n",
    "\n",
    "def commons_heuristic(name:str)->str:\n",
    "    \"\"\"Return given `name` with applied commons heuristic.\n",
    "        name:str, the name to which apply the heuristic.\n",
    "    \"\"\"\n",
    "    drop = \"\\(mse\\)\", \"total[\\w]+\"\n",
    "    for d in drop:\n",
    "        name = re.sub(d, \"\", name)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columns_heuristics(name):\n",
    "    \"\"\"Return given `name` with applied batch of heuristics.\n",
    "        name:str, the name to which apply the heuristics.\n",
    "    \"\"\"\n",
    "    heuristics = [\n",
    "        vitamins_heuristic,\n",
    "        fats_heuristic,\n",
    "        commons_heuristic\n",
    "    ]\n",
    "    for heuristic in heuristics:\n",
    "        name = heuristic(name)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(corpus:List[str], texts:List[np.ndarray], heuristics:Callable[[np.ndarray],np.ndarray]=None):\n",
    "    \"\"\"Return tfidf vectorization using given `corpus` vector. If given, also applies heuristics element-wise.\n",
    "        corpus:List[str], list of texts to use as baseline for tfidf.\n",
    "        texts:List[np.ndarray], list of vectors to which apply heuristics and tfidf vectorization element-wise.\n",
    "        heuristics:Callable[[np.ndarray],np.ndarray], function to apply heauristics to texts.\n",
    "    \"\"\"\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectorizer.fit(corpus)\n",
    "    if heuristics is not None:\n",
    "        texts = [heuristics(t) for t in texts]\n",
    "    return [vectorizer.transform(t) for t in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_matrix_sum(A, B):\n",
    "    return np.nansum(\n",
    "        [A.reshape(A.shape[0], 1, A.shape[1]),\n",
    "         B.reshape(1, *B.shape)], axis=0)\n",
    "\n",
    "\n",
    "def pairwise_vector_sum(A, B):\n",
    "    Ar = A.reshape(-1, 1)\n",
    "    Br = B.reshape(1, B.size)\n",
    "    if A.size==1:\n",
    "        return np.nansum([Ar, Br.T], axis=0).T \n",
    "    return np.nansum([Ar, Br], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mse(A, B):\n",
    "    normalization = pairwise_matrix_sum(A, B)\n",
    "    difference = np.abs(pairwise_matrix_sum(A, -B))\n",
    "    mask = np.logical_or(np.isnan(normalization), normalization == 0)\n",
    "    return np.nanmean(np.divide(difference, normalization, where=~mask), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mean_differences(A: np.matrix, B: np.matrix) -> np.matrix:\n",
    "    \"\"\"Return weighted mean differences of given matrices.\"\"\"\n",
    "    if not A.shape[1] or not A.shape[1]:\n",
    "        return np.zeros((A.shape[1], B.shape[1]))\n",
    "    X, Y = np.nanmean(A.values, axis=0), np.nanmean(B.values, axis=0)\n",
    "    N, M = np.sum(pd.notna(A.values), axis=0), np.sum(pd.notna(B.values), axis=0)\n",
    "    return np.abs((pairwise_vector_sum(X, -Y) * pairwise_vector_sum(N, -M)) /\n",
    "                  (pairwise_vector_sum(X, Y) + pairwise_vector_sum(N, M)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columns_to_type_groups(df):\n",
    "    types = df.columns.to_series().groupby(df.dtypes).groups\n",
    "    string = float64 = []\n",
    "    if np.dtype('O') in types:\n",
    "        string = types[np.dtype('O')]\n",
    "    if np.dtype('float64') in types:\n",
    "        float64 = types[np.dtype('float64')]\n",
    "        \n",
    "    return df[string], df[float64]\n",
    "\n",
    "def matrix_type_argsort(matrix:np.matrix, df:pd.DataFrame)->np.matrix:\n",
    "    \"\"\"Return given `matrix` sorted using given `df` DataFrame types.\"\"\"\n",
    "    return matrix[list(zip(*sorted(zip(df.dtypes, range(len(df.dtypes))))))[1],:]\n",
    "\n",
    "def matrix_double_type_argsort(floats:np.matrix, strings:np.matrix, df1:pd.DataFrame, df2:pd.DataFrame)->np.matrix:\n",
    "    \"\"\"Return combined matrix sorted in both axis using given dataframes types.\"\"\"\n",
    "    ground = np.zeros(np.sum([floats.shape, strings.shape], axis=0))\n",
    "    if np.all(floats.shape):\n",
    "        ground[:floats.shape[0], :floats.shape[1]] = floats\n",
    "    if np.all(strings.shape):\n",
    "        ground[-strings.shape[0]:, -strings.shape[1]:] = strings\n",
    "    return matrix_type_argsort(matrix_type_argsort(ground, df1).T, df2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_mean(matrix):\n",
    "    if matrix.shape[0]==0 or matrix.shape[1]==0:\n",
    "        return matrix\n",
    "    matrix[np.isclose(matrix, np.nanmax(matrix))] = np.nan\n",
    "    matrix[np.isinf(matrix)] = np.nan\n",
    "    matrix[matrix >= np.nanmean(matrix)] = np.inf\n",
    "    matrix[np.isnan(matrix)] = np.inf\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def filter_mask(matrix):\n",
    "    if matrix.shape[0]==0 or matrix.shape[1]==0:\n",
    "        return matrix\n",
    "    return np.all([np.all(\n",
    "        [\n",
    "            matrix == np.min(matrix, axis=1).reshape(-1, 1), matrix == np.min(\n",
    "                matrix, axis=0)\n",
    "        ],\n",
    "        axis=0), ~np.isinf(matrix)], axis=0)\n",
    "\n",
    "\n",
    "def drop_nan(df):\n",
    "    return [df[c].dropna() for c in df]\n",
    "\n",
    "\n",
    "def column_values_mean_tfidf_distance(df1: pd.DataFrame,\n",
    "                                      df2: pd.DataFrame) -> np.matrix:\n",
    "    \"\"\"Return cosine distance of dataframes columns mean tfidf vectorization.\n",
    "        df1:pd.DataFrame, first string only dataframe.\n",
    "        df2:pd.DataFrame, second string only dataframe.\n",
    "    \"\"\"\n",
    "    if not df1.shape[1] or not df2.shape[1]:\n",
    "        return np.zeros((df1.shape[1], df2.shape[1]))\n",
    "    corpus = pd.concat(\n",
    "        [df[c].dropna() for df in [df1, df2] for c in df.columns])\n",
    "    vectors = tfidf(corpus, [*drop_nan(df1), *drop_nan(df2)])\n",
    "    mean_vectors = np.array([np.mean(v, axis=0) for v in vectors])\n",
    "    mean_vectors = mean_vectors.reshape(mean_vectors.shape[0],\n",
    "                                        mean_vectors.shape[-1])\n",
    "    return euclidean_distances(mean_vectors[:df1.shape[1]],\n",
    "                                mean_vectors[df1.shape[1]:])\n",
    "\n",
    "\n",
    "def tfidf_distance(corpus: List[str],\n",
    "                   A: np.ndarray,\n",
    "                   B: np.ndarray,\n",
    "                   heuristics: Callable = None) -> np.matrix:\n",
    "    \"\"\"Return cosine distance of dataframes columns mean tfidf vectorization.\n",
    "        corpus:List[str], list of texts to use as baseline for tfidf.\n",
    "        A:np.ndarray, vector to which apply heuristics and tfidf vectorization element-wise.\n",
    "        B:np.ndarray, vector to which apply heuristics and tfidf vectorization element-wise.\n",
    "        heuristics:Callable[[np.ndarray],np.ndarray], function to apply heauristics to texts.\n",
    "    \"\"\"\n",
    "    return euclidean_distances(*tfidf(corpus, [A, B], heuristics))\n",
    "\n",
    "\n",
    "def units_mask(A: np.ndarray, B: np.ndarray):\n",
    "    sep = \" | \"\n",
    "    unit_A, unit_B = [\n",
    "        np.array(\n",
    "            [None if len(c.split(sep)) == 1 else c.split(sep)[1] for c in v])\n",
    "        for v in [A, B]\n",
    "    ]\n",
    "    return unit_A[:, None] == unit_B\n",
    "\n",
    "\n",
    "def sub_incidence_matrix(corpus: List[str], A: pd.DataFrame, B: pd.DataFrame,\n",
    "                         heuristics: Callable[[np.ndarray], np.ndarray]):\n",
    "    strings, floats = list(\n",
    "        zip(columns_to_type_groups(A), columns_to_type_groups(B)))\n",
    "    return np.all(\n",
    "        [\n",
    "            np.all(\n",
    "                [\n",
    "                    #matrix_double_type_argsort(*[\n",
    "                    #    filter_mask(filter_mean(m)) for m in [\n",
    "                    #        weighted_mean_differences(*floats),\n",
    "                    #        column_values_mean_tfidf_distance(*strings)\n",
    "                    #    ]\n",
    "                    #], A, B),\n",
    "                    filter_mask(filter_mean(tfidf_distance(corpus, A.columns, B.columns, heuristics)))\n",
    "                ],\n",
    "                axis=0),\n",
    "            units_mask(A.columns, B.columns)\n",
    "        ],\n",
    "        axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incidence_matrix(corpus:List[str], dataframes:List[pd.DataFrame], heuristics:Callable):\n",
    "    n = sum([df.shape[1] for df in dataframes])\n",
    "    ground = np.zeros((n, n))\n",
    "    old = np.array([0, 0])\n",
    "    offset = 0\n",
    "    for i, df1 in enumerate(dataframes):\n",
    "        old[1] = offset\n",
    "        for j, df2 in enumerate(dataframes[i:], i):\n",
    "            if i == j:\n",
    "                matrix = np.eye(df1.shape[1])\n",
    "            else:\n",
    "                matrix = sub_incidence_matrix(corpus, df1, df2, heuristics)\n",
    "            x = slice(old[0], old[0] + df1.shape[1])\n",
    "            y = slice(old[1], old[1] + df2.shape[1])\n",
    "            ground[x, y] = matrix\n",
    "            ground[y, x] = matrix.T\n",
    "            old[1] += df2.shape[1]\n",
    "        offset += df1.shape[1]\n",
    "        old[0] += df1.shape[1]\n",
    "\n",
    "    return ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching(dataframes: List[pd.DataFrame], heuristics: Callable):\n",
    "    corpus = heuristics(np.array([c for df in dataframes for c in df.columns]))\n",
    "    M = incidence_matrix(heuristics(columns), dataframes, heuristics)\n",
    "    return M\n",
    "    shapes = [df.shape[1] for df in dataframes]\n",
    "    m = np.repeat(np.arange(len(dataframes)), shapes)\n",
    "    for i, row in enumerate(M):\n",
    "        for j, value in enumerate(row):\n",
    "            if value:\n",
    "                first = np.nonzero(row)[0][0]\n",
    "                df1 = dataframes[m[first]]\n",
    "                df2 = dataframes[m[j]]\n",
    "                old = df2.columns[j - sum(shapes[:m[j]])]\n",
    "                new = df1.columns[first - sum(shapes[:m[first]])]\n",
    "                if old != new:\n",
    "                    dataframes[m[j]] = dataframes[m[j]].rename(\n",
    "                        columns={\n",
    "                            old:new\n",
    "                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../sanitized_csv/\"\n",
    "csvs = [\n",
    "    csv\n",
    "    for path, dirs, csvs in os.walk(path)\n",
    "    for csv in csvs if \"svizz\" not in csv\n",
    "]\n",
    "dataframes = [\n",
    "    pd.read_csv(\"{path}/{csv}\".format(path=path, csv=csv), index_col=[\"name\"])\n",
    "    for csv in csvs\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: Mean of empty slice\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "M = matching(dataframes, np.vectorize(columns_heuristics, otypes=[str]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acqua | g' 'acqua | g' 'acqua | g' 'acqua | g' 'acqua | g']\n",
      "['calorie | kcal' 'calorie | kcal']\n",
      "['fibra alimentare | g' 'fibra alimentare | g'\n",
      " 'fibra alimentare totale | g']\n",
      "['proteine totali | g' 'proteine | g' 'proteine | g' 'proteine | g'\n",
      " 'proteine totali | g' 'proteine | g' 'proteine | g']\n",
      "['proteine animali | g' 'proteine animali | g']\n",
      "['proteine vegetali | g' 'proteine vegetali | g']\n",
      "['amido | g' 'amido (mse) | g' 'amido | g']\n",
      "['lipidi totali | g' 'lipidi totali | g' 'lipidi totali | g' 'lipidi | g']\n",
      "['lipidi animali | g' 'lipidi animali | g']\n",
      "['lipidi vegetali | g' 'lipidi vegetali | g']\n",
      "['acido oleico | g' 'acido oleico | g']\n",
      "['monoinsaturi totali | g' 'monoinsaturi totali | g'\n",
      " 'acidi grassi monoinsaturi totali | g']\n",
      "['acido linoleico | g' 'acido linoleico | g']\n",
      "['acido linolenico | g' 'acido linolenico | g']\n",
      "['altri polinsaturi | g' 'altri acidi grassi polinsaturi | g']\n",
      "['polinsaturi totali | g' 'polinsaturi totali | g'\n",
      " 'acidi grassi polinsaturi totali | g']\n",
      "['colesterolo | g' 'colesterolo | g' 'colesterolo | g' 'colesterolo | g'\n",
      " 'colesterolo | g' 'colesterolo | g']\n",
      "['ferro | g' 'ferro | g' 'ferro | g' 'ferro | g' 'ferro | g']\n",
      "['calcio | g' 'calcio | g' 'calcio | g' 'calcio | g' 'calcio | g']\n",
      "['sodio | g' 'sodio | g' 'sodio | g' 'sodio | g' 'sodio | g' 'sodio | g']\n",
      "['potassio | g' 'potassio | g' 'potassio | g' 'potassio | g'\n",
      " 'potassio | g']\n",
      "['fosforo | g' 'fosforo | g' 'fosforo | g' 'fosforo | g' 'fosforo | g']\n",
      "['zinco | g' 'zinco | g' 'zinco | g' 'zinco | g' 'zinco | g']\n",
      "['tiamina (vitamina b1) | g' 'vitamina b1, tiamina | g']\n",
      "['vitamina b6 | g' 'vitamina b6 | g' 'vitamina b6 | g']\n",
      "['riboflavina | g' 'riboflavina | g' 'vitamina b2, riboflavina | g'\n",
      " 'riboflavina | g']\n",
      "['niacina (vitamina pp) | g' 'niacina | g']\n",
      "['vitamina c | g' 'vitamina c | g' 'vitamina c | g' 'vitamina c | g'\n",
      " 'vitamina c | g']\n",
      "['retinolo | g' 'retinolo | g']\n",
      "['carotene | g' 'ÃŸ-carotene eq. | g']\n",
      "['vitamina d | g' 'vitamina d | g' 'vitamina d | g']\n",
      "['vitamina e | g' 'vitamina e (ate) | g' 'vitamina e | g']\n",
      "['carboidrati | g' 'carboidrati | g' 'carboidrati disponibili (mse) | g'\n",
      " 'carboidrati solubili (mse) | g' 'carboidrati | g']\n",
      "['category' 'category' 'category']\n",
      "['fillochinone (vitamina k) | g' 'vitamina k | g']\n",
      "['grassi | g' 'grassi | g' 'grassi | g' 'grassi | g']\n",
      "['acidi grassi saturi | g' 'acidi grassi saturi totali | g']\n",
      "['zuccheri | g' 'zuccheri | g' 'zuccheri solubili | g']\n",
      "['acido aspartico | g' 'acido aspartico | g' 'acido aspartico | g']\n",
      "['acido glutamico | g' 'acido glutamico | g']\n",
      "['alanina | g' 'alanina | g' 'alanina | g']\n",
      "['alcol | g' 'alcol | g' 'alcol | g']\n",
      "['arginina | g' 'arginina | g' 'arginina | g']\n",
      "['c12:0 | g' 'c12:0 | g']\n",
      "['c14:0 | g' 'c14:0 | g']\n",
      "['c14:1 | g' 'c14:1 | g']\n",
      "['c16:0 | g' 'c16:0 | g']\n",
      "['c16:1 | g' 'c16:1 | g']\n",
      "['c18:0 | g' 'c18:0 | g']\n",
      "['c18:1 | g' 'c18:1 | g']\n",
      "['c18:2 | g' 'c18:2 | g']\n",
      "['c18:3 | g' 'c18:3 | g']\n",
      "['c20:0 | g' 'c20:0 | g']\n",
      "['c20:1 | g' 'c20:1 | g']\n",
      "['c20:4 | g' 'c20:4 | g']\n",
      "['c20:5 | g' 'c20:5 | g']\n",
      "['c22:0 | g' 'c22:0 | g']\n",
      "['c22:1 | g' 'c22:1 | g']\n",
      "['c22:6 | g' 'c22:6 | g']\n",
      "['carboidrati disponibili | g' 'carboidrati disponibili | g']\n",
      "['cistina | g' 'cistina | g' 'cistina | g']\n",
      "['fenilalanina | g' 'fenilalanina | g' 'fenilalanina | g']\n",
      "['fibra insolubile | g' 'fibra insolubile | g']\n",
      "['fibra solubile | g' 'fibra solubile | g']\n",
      "['fibra totale | g' 'fibra totale | g']\n",
      "['glicina | g' 'glicina | g' 'glicina | g']\n",
      "['isoleucina | g' 'isoleucina | g' 'isoleucina | g']\n",
      "['istidina | g' 'istidina | g' 'istidina | g']\n",
      "['leucina | g' 'leucina | g' 'leucina | g']\n",
      "['lisina | g' 'lisina | g' 'lisina | g']\n",
      "['magnesio | g' 'magnesio | g' 'magnesio | g' 'magnesio | g']\n",
      "['metionina | g' 'metionina | g' 'metionina | g']\n",
      "['niacina | g' 'niacina | g']\n",
      "['parte edibile | %' 'parte edibile | %']\n",
      "['prolina | g' 'prolina | g' 'prolina | g']\n",
      "['rame | g' 'rame | g' 'rame | g' 'rame | g']\n",
      "['serina | g' 'serina | g' 'serina | g']\n",
      "['tiamina | g' 'tiamina | g']\n",
      "['tirosina | g' 'tirosina | g' 'tirosina | g']\n",
      "['treonina | g' 'treonina | g' 'treonina | g']\n",
      "['triptofano | g' 'triptofano | g' 'triptofano | g']\n",
      "['valina | g' 'valina | g' 'valina | g']\n",
      "['vitamina a retinolo eq. | g' 'vitamina a retinolo eq. | g']\n",
      "['calorie | kcal' 'energia, ricalcolata | kcal']\n",
      "['manganese | g' 'manganese | g']\n",
      "['selenio | g' 'selenio | g']\n",
      "['vitamina b12 | g' 'vitamina b12 | g']\n"
     ]
    }
   ],
   "source": [
    "dense_A = M\n",
    "for i, row in enumerate(dense_A):\n",
    "    if np.sum(row) > 1:\n",
    "        rows = np.where(row)\n",
    "        dense_A[rows] = 0 \n",
    "        dense_A[:,rows] = 0 \n",
    "        print(columns[rows])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dense_A = A.todense()\n",
    "old_A = dense_A\n",
    "for i in tqdm(range(100000)):\n",
    "    dense_A = dense_A**2\n",
    "    dense_A[dense_A>1] = 1\n",
    "    if (old_A == dense_A).all():\n",
    "        break\n",
    "    old_A = dense_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
