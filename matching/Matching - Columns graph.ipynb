{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_distances\n",
    "from pyscipopt import Model, quicksum\n",
    "from scipy.sparse import csr_matrix\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from typing import List, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vitamins_heuristic(name:str)->str:\n",
    "    \"\"\"Return given `name` with applied vitamin heuristic.\n",
    "        name:str, the name to which apply the heuristic.\n",
    "    \"\"\"\n",
    "    return re.sub(\"(vitamina?) ([a-z\\d]+)\", r\"\\1_\\2\", name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columns_heuristics(name):\n",
    "    \"\"\"Return given `name` with applied batch of heuristics.\n",
    "        name:str, the name to which apply the heuristics.\n",
    "    \"\"\"\n",
    "    heuristics = [\n",
    "        vitamins_heuristic\n",
    "    ]\n",
    "    for heuristic in heuristics:\n",
    "        name = heuristic(name)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(corpus:List[str], texts:List[np.ndarray], heuristics:Callable[[np.ndarray],np.ndarray]=None):\n",
    "    \"\"\"Return tfidf vectorization using given `corpus` vector. If given, also applies heuristics element-wise.\n",
    "        corpus:List[str], list of texts to use as baseline for tfidf.\n",
    "        texts:List[np.ndarray], list of vectors to which apply heuristics and tfidf vectorization element-wise.\n",
    "        heuristics:Callable[[np.ndarray],np.ndarray], function to apply heauristics to texts.\n",
    "    \"\"\"\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectorizer.fit(corpus)\n",
    "    if heuristics is not None:\n",
    "        texts = [heuristics(t) for t in texts]\n",
    "    return [vectorizer.transform(t) for t in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_matrix_sum(A, B):\n",
    "    return np.nansum(\n",
    "        [A.reshape(A.shape[0], 1, A.shape[1]),\n",
    "         B.reshape(1, *B.shape)], axis=0)\n",
    "\n",
    "\n",
    "def pairwise_vector_sum(A, B):\n",
    "    Ar = A.reshape(-1, 1)\n",
    "    Br = B.reshape(1, B.size)\n",
    "    if A.size==1:\n",
    "        return np.nansum([Ar, Br.T], axis=0).T \n",
    "    return np.nansum([Ar, Br], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mse(A, B):\n",
    "    normalization = pairwise_matrix_sum(A, B)\n",
    "    difference = np.abs(pairwise_matrix_sum(A, -B))\n",
    "    mask = np.logical_or(np.isnan(normalization), normalization == 0)\n",
    "    return np.nanmean(np.divide(difference, normalization, where=~mask), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mean_differences(A: np.matrix, B: np.matrix) -> np.matrix:\n",
    "    \"\"\"Return weighted mean differences of given matrices.\"\"\"\n",
    "    if not A.shape[1] or not A.shape[1]:\n",
    "        return np.zeros((A.shape[1], B.shape[1]))\n",
    "    X, Y = np.nanmean(A.values, axis=0), np.nanmean(B.values, axis=0)\n",
    "    N, M = np.sum(pd.notna(A.values), axis=0), np.sum(pd.notna(B.values), axis=0)\n",
    "    return filter_mask(filter_mean(np.abs((pairwise_vector_sum(X, -Y) * pairwise_vector_sum(N, -M)) /\n",
    "                  (pairwise_vector_sum(X, Y) + pairwise_vector_sum(N, M)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columns_to_type_groups(df):\n",
    "    types = df.columns.to_series().groupby(df.dtypes).groups\n",
    "    string = float64 = []\n",
    "    if np.dtype('O') in types:\n",
    "        string = types[np.dtype('O')]\n",
    "    if np.dtype('float64') in types:\n",
    "        float64 = types[np.dtype('float64')]\n",
    "        \n",
    "    return df[string], df[float64]\n",
    "\n",
    "def matrix_type_argsort(matrix:np.matrix, df:pd.DataFrame)->np.matrix:\n",
    "    \"\"\"Return given `matrix` sorted using given `df` DataFrame types.\"\"\"\n",
    "    return matrix[list(zip(*sorted(zip(df.dtypes, range(len(df.dtypes))))))[1],:]\n",
    "\n",
    "def matrix_double_type_argsort(floats:np.matrix, strings:np.matrix, df1:pd.DataFrame, df2:pd.DataFrame)->np.matrix:\n",
    "    \"\"\"Return combined matrix sorted in both axis using given dataframes types.\"\"\"\n",
    "    ground = np.zeros(np.sum([floats.shape, strings.shape], axis=0))\n",
    "    if np.all(floats.shape):\n",
    "        ground[:floats.shape[0], :floats.shape[1]] = floats\n",
    "    if np.all(strings.shape):\n",
    "        ground[-strings.shape[0]:, -strings.shape[1]:] = strings\n",
    "    return matrix_type_argsort(matrix_type_argsort(ground, df1).T, df2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_mean(matrix):\n",
    "    matrix[np.isclose(matrix, np.nanmax(matrix))] = np.nan\n",
    "    matrix[np.isinf(matrix)] = np.nan\n",
    "    matrix[matrix >= np.nanmean(matrix)] = np.inf\n",
    "    matrix[np.isnan(matrix)] = np.inf\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def filter_mask(matrix):\n",
    "    return np.all(\n",
    "        [\n",
    "            matrix == np.min(matrix, axis=1).reshape(-1, 1), matrix == np.min(\n",
    "                matrix, axis=0), ~np.isinf(matrix)\n",
    "        ],\n",
    "        axis=0)\n",
    "\n",
    "\n",
    "def drop_nan(df):\n",
    "    return [df[c].dropna() for c in df]\n",
    "\n",
    "\n",
    "def column_values_mean_tfidf_distance(df1: pd.DataFrame,\n",
    "                                      df2: pd.DataFrame) -> np.matrix:\n",
    "    \"\"\"Return cosine distance of dataframes columns mean tfidf vectorization.\n",
    "        df1:pd.DataFrame, first string only dataframe.\n",
    "        df2:pd.DataFrame, second string only dataframe.\n",
    "    \"\"\"\n",
    "    if not df1.shape[1] or not df2.shape[1]:\n",
    "        return np.zeros((df1.shape[1], df2.shape[1]))\n",
    "    corpus = pd.concat(\n",
    "        [df[c].dropna() for df in [df1, df2] for c in df.columns])\n",
    "    vectors = tfidf(corpus, [*drop_nan(df1), *drop_nan(df2)])\n",
    "    mean_vectors = np.array([np.mean(v, axis=0) for v in vectors])\n",
    "    mean_vectors = mean_vectors.reshape(mean_vectors.shape[0],\n",
    "                                        mean_vectors.shape[-1])\n",
    "    return filter_mask(\n",
    "        filter_mean(\n",
    "            euclidean_distances(mean_vectors[:df1.shape[1]],\n",
    "                             mean_vectors[df1.shape[1]:])))\n",
    "\n",
    "\n",
    "def tfidf_distance(corpus: List[str],\n",
    "                   A: np.ndarray,\n",
    "                   B: np.ndarray,\n",
    "                   heuristics: Callable = None) -> np.matrix:\n",
    "    \"\"\"Return cosine distance of dataframes columns mean tfidf vectorization.\n",
    "        corpus:List[str], list of texts to use as baseline for tfidf.\n",
    "        A:np.ndarray, vector to which apply heuristics and tfidf vectorization element-wise.\n",
    "        B:np.ndarray, vector to which apply heuristics and tfidf vectorization element-wise.\n",
    "        heuristics:Callable[[np.ndarray],np.ndarray], function to apply heauristics to texts.\n",
    "    \"\"\"\n",
    "    return filter_mask(\n",
    "        filter_mean(euclidean_distances(*tfidf(corpus, [A, B], heuristics))))\n",
    "\n",
    "\n",
    "def units_mask(A: np.ndarray, B: np.ndarray):\n",
    "    sep = \" | \"\n",
    "    unit_A, unit_B = [np.array([\n",
    "        None if len(c.split(sep)) == 1 else c.split(sep)[1] for c in v\n",
    "    ]) for v in [A, B]]\n",
    "    return unit_A[:,None] == unit_B\n",
    "\n",
    "def sub_incidence_matrix(corpus: List[str], A: pd.DataFrame, B: pd.DataFrame,\n",
    "                         heuristics: Callable[[np.ndarray], np.ndarray]):\n",
    "    strings, floats = list(\n",
    "        zip(columns_to_type_groups(A), columns_to_type_groups(B)))\n",
    "    return np.all([np.all(\n",
    "        [\n",
    "            matrix_double_type_argsort(\n",
    "                weighted_mean_differences(*floats),\n",
    "                column_values_mean_tfidf_distance(*strings), A, B),\n",
    "            tfidf_distance(corpus, A.columns, B.columns, heuristics)\n",
    "        ],\n",
    "        axis=0), units_mask(A.columns, B.columns)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incidence_matrix(corpus, dataframes, heuristics):\n",
    "    n = sum([df.shape[1] for df in dataframes])\n",
    "    ground = np.zeros((n, n))\n",
    "    old = np.array([0, 0])\n",
    "    offset = 0\n",
    "    for i, df1 in enumerate(dataframes):\n",
    "        old[1] = offset\n",
    "        for j, df2 in enumerate(dataframes[i:], i):\n",
    "            if i == j:\n",
    "                matrix = np.eye(df1.shape[1])\n",
    "            else:\n",
    "                matrix = sub_incidence_matrix(corpus, df1, df2, heuristics)\n",
    "            x = slice(old[0], old[0] + df1.shape[1])\n",
    "            y = slice(old[1], old[1] + df2.shape[1])\n",
    "            ground[x, y] = matrix\n",
    "            ground[y, x] = matrix.T\n",
    "            old[1] += df2.shape[1]\n",
    "        offset += df1.shape[1]\n",
    "        old[0] += df1.shape[1]\n",
    "\n",
    "    return csr_matrix(ground)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../sanitized_csv/\"\n",
    "csvs = [\n",
    "    csv\n",
    "    for path, dirs, csvs in os.walk(path)\n",
    "    for csv in csvs\n",
    "]\n",
    "dataframes = [\n",
    "    pd.read_csv(\"{path}/{csv}\".format(path=path, csv=csv), index_col=[\"name\"])\n",
    "    for csv in csvs\n",
    "]\n",
    "columns = np.array([c for df in dataframes for c in df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confederazione_svizzera.csv\n"
     ]
    }
   ],
   "source": [
    "for csv, df in zip(csvs, dataframes):\n",
    "    for c in df.columns:\n",
    "        if \"phosphorus\" in c:\n",
    "            print(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  after removing the cwd from sys.path.\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: Mean of empty slice\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "A = incidence_matrix(columns, dataframes, np.vectorize(columns_heuristics, otypes=[str]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c7e6d74616d4e93a87d03eae3eb2b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=100000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dense_A = A.todense()\n",
    "old_A = dense_A\n",
    "for i in tqdm(range(100000)):\n",
    "    dense_A = dense_A**2\n",
    "    dense_A[dense_A>1] = 1\n",
    "    if (old_A == dense_A).all():\n",
    "        break\n",
    "    old_A = dense_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acqua | g' 'acqua | g' 'acqua | g' 'acqua | g' 'acqua | g']\n",
      "['calorie | kcal' 'calorie | kcal' 'calorie | kcal']\n",
      "['fibra alimentare | g' 'fibra alimentare totale | g']\n",
      "['lipidi animali | g' 'lipidi animali | g']\n",
      "['lipidi vegetali | g' 'lipidi vegetali | g']\n",
      "['monoinsaturi totali | g' 'acidi grassi monoinsaturi totali | g']\n",
      "['acido linoleico | g' 'acido linoleico | g']\n",
      "['colesterolo | g' 'colesterolo | g' 'colesterolo | g']\n",
      "['ferro | g' 'ferro | g']\n",
      "['potassio | g' 'potassio | g' 'potassio | g']\n",
      "['fosforo | g' 'fosforo | g']\n",
      "['tiamina (vitamina b1) | g' 'vitamina b1, tiamina | g']\n",
      "['niacina (vitamina pp) | g' 'niacina | g']\n",
      "['vitamina c | g' 'vitamina c | g' 'vitamina c | g']\n",
      "['vitamina d | g' 'vitamina d | g']\n",
      "['proteine | g' 'proteine | g']\n",
      "['alcol | g' 'alcol | g']\n",
      "['c20:5 | g' 'c20:1 | g']\n",
      "['acido aspartico | g' 'acido aspartico | g']\n",
      "['alanina | g' 'alanina | g']\n",
      "['vitamina b6 | g' 'vitamina k | g']\n"
     ]
    }
   ],
   "source": [
    "dense_A = A.todense()\n",
    "for i, row in enumerate(dense_A):\n",
    "    if np.sum(row) > 1:\n",
    "        rows = np.where(row)[1]\n",
    "        dense_A[rows] = 0 \n",
    "        print(columns[rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
