{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import re\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from IPython.display import display\n",
    "regex = r\"(\\([^\\)]+\\))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../raw/www.my-personaltrainer.it\"\n",
    "foods = [food for food in os.listdir(path) if food[0] != \".\"]\n",
    "tables = [table.split(\".csv\")[0] for table in os.listdir(\"{path}/{food}\".format(path=path, food=foods[0])) if table.endswith(\".csv\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_value(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    if \"%\" in value:\n",
    "        if value[:-1] == \"\":\n",
    "            return np.nan\n",
    "        return float(value[:-1].replace(\",\",\".\"))\n",
    "    if \"Âµg\" in value:\n",
    "        return float(value[:-2].replace(\",\",\".\")) * 1e-6\n",
    "    if \"mg\" in value:\n",
    "        return float(value[:-2].replace(\",\",\".\")) * 1e-3\n",
    "    if \"g\" in value:\n",
    "        return float(value[:-1].replace(\",\",\".\"))\n",
    "    if value.replace('.','',1).isdigit():\n",
    "        return float(value)\n",
    "    if value.lower() == \"tr\":\n",
    "        return 0\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_proteins(food):\n",
    "    file_path = \"{path}/{name}/{table}.csv\".format(path=path, name=food, table=1)\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df.iloc[1:] # Drop the titles\n",
    "    df.iloc[0,3] = df.iloc[0][2] # set the formatted percentage in the right cell\n",
    "    df = df.iloc[:,[1,3]]    # drop the useless columns\n",
    "    df = df.set_index(\"0\")\n",
    "\n",
    "    parsed_values = []\n",
    "    renamer = {}\n",
    "    for name, (value) in df.iterrows():\n",
    "        value = value[0]\n",
    "        old_name = name\n",
    "        \n",
    "        name = name.lower().strip()\n",
    "        name = re.sub(regex, \"\", name, 0, re.MULTILINE)\n",
    "        name = name.replace(\":\",\" \")\n",
    "        name = name.replace(\"  \",\" \")\n",
    "        \n",
    "        if \"%\" in name or (not pd.isna(value) and \"%\" in value):\n",
    "            renamer[old_name] = name + \" | %\"\n",
    "        else:\n",
    "            renamer[old_name] = name + \" | g\"\n",
    "            \n",
    "        renamer[old_name] = renamer[old_name].replace(\"  \",\" \")\n",
    "\n",
    "        parsed_values.append(parse_value(value))\n",
    "\n",
    "    df = df.rename(columns={\"2\":\"1\"})\n",
    "    df = df.rename(index=renamer) # rename the columns\n",
    "    df.iloc[:,[0]] = np.array(parsed_values).reshape((len(df),1)) # update the dataframe with the new parsed data\n",
    "    return df.astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_general(food):\n",
    "    file_path = \"{path}/{name}/{table}.csv\".format(path=path, name=food, table=0)\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df.iloc[1:] # Drop the titles\n",
    "    df = df.iloc[:,[1,2]] # Drop the RDA col\n",
    "    df = df.set_index(\"0\") # Set the first col as the index\n",
    "    parsed_values = []\n",
    "    renamer = {}\n",
    "    for name, (value) in df.iterrows():\n",
    "        value = value[0]\n",
    "        old_name = name\n",
    "    \n",
    "        name = name.lower().strip()\n",
    "        name = re.sub(regex, \"\", name, 0, re.MULTILINE)\n",
    "        name = name.replace(\"  \",\" \")\n",
    "        \n",
    "        if \"%\" in name or (not pd.isna(value) and \"%\" in value):\n",
    "            renamer[old_name] = name + \" | %\"\n",
    "        else:\n",
    "            renamer[old_name] = name + \" | g\"\n",
    "            \n",
    "        renamer[old_name] = renamer[old_name].replace(\"  \",\" \")\n",
    "\n",
    "        parsed_values.append(parse_value(value))\n",
    "\n",
    "\n",
    "    df = df.rename(index=renamer) # rename the columns\n",
    "    df.iloc[:,[0]] = np.array(parsed_values).reshape((len(df),1)) # update the dataframe with the new parsed data\n",
    "    return df.astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fats(food):\n",
    "    file_path = \"{path}/{name}/{table}.csv\".format(path=path, name=food, table=2)\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df.iloc[1:] # Drop the titles\n",
    "    df = df.iloc[:,[1,2]] # Drop the index col\n",
    "    df = df.set_index(\"0\") # Set the first col as the index\n",
    "\n",
    "    parsed_values = []\n",
    "    renamer = {}\n",
    "    for name, (value) in df.iterrows():\n",
    "        value = value[0]\n",
    "        old_name = name\n",
    "        \n",
    "        \n",
    "        if name[0] == \"C\": # Grassi\n",
    "            name = name.replace(\" \",\":\")\n",
    "\n",
    "        name = name.lower().strip()\n",
    "        name = re.sub(regex, \"\", name, 0, re.MULTILINE) \n",
    "        name = name.replace(\"  \",\" \")\n",
    "        \n",
    "        if \"%\" in name or (not pd.isna(value) and \"%\" in value):    \n",
    "            renamer[old_name] = name + \" | %\"\n",
    "        else: \n",
    "            renamer[old_name] = name + \" | g\"\n",
    "        \n",
    "        renamer[old_name] = renamer[old_name].replace(\"  \",\" \")\n",
    "        \n",
    "        parsed_values.append(parse_value(value))\n",
    "\n",
    "\n",
    "    df = df.rename(index=renamer) # rename the columns\n",
    "    df.iloc[:,[0]] = np.array(parsed_values).reshape((len(df),1)) # update the dataframe with the new parsed data\n",
    "    return df.astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_category(food):\n",
    "    file_path = \"{path}/{name}/metadata.json\".format(path=path, name=food)\n",
    "    with open(file_path,\"r\") as f:\n",
    "        dic = json.load(f)  \n",
    "    df = pd.DataFrame(dic[\"category\"],[\"category\"],[\"1\"])\n",
    "    df.columns.name = \"name\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_row(food):\n",
    "    proteins, general, fats, category = parse_proteins(food), parse_general(food), parse_fats(food), parse_category(food)\n",
    "    single_row = pd.concat([general,proteins,fats,category]).T\n",
    "    single_row = single_row.rename({\"1\":food})\n",
    "    single_row = single_row.iloc[:,~single_row.columns.duplicated()]\n",
    "    del single_row.columns.name\n",
    "    return single_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28fbd2525b9a4cafb3b0b248228b3f66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=706), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with Pool(cpu_count()) as p:\n",
    "    mpt = pd.concat(list(tqdm(p.imap(get_single_row, foods), total=len(foods))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop rows without required columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_columns = [\n",
    "    \"acqua | g\", \"carboidrati disponibili | g\", \"proteine | g\", \"grassi | g\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5603576487252124"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(pd.isna(mpt.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpt = mpt.drop(index=mpt.index[np.any(pd.isna(mpt[required_columns]), axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5577830188679245"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(pd.isna(mpt.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize to 100g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "grams = [\n",
    "    'acqua | g', 'carboidrati disponibili | g', 'proteine | g', 'grassi | g',\n",
    "    'fibra totale | g', 'alcol | g', 'sodio | g', 'potassio | g', 'ferro | g',\n",
    "    'calcio | g', 'fosforo | g', 'magnesio | g', 'zinco | g', 'rame | g',\n",
    "    'selenio | g', 'tiamina | g', 'riboflavina | g', 'niacina | g',\n",
    "    'vitamina a retinolo eq. | g', 'vitamina c | g', 'vitamina e | g',\n",
    "    'vitamina b6 | g', 'vitamina b12 | g', 'manganese | g'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_normalize = list(set(mpt.columns) - set([\"category\", \"parte edibile | %\", \"proteine | %\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _and(*args):\n",
    "    return np.all(args, axis=0)\n",
    "\n",
    "def _or(*args):\n",
    "    return np.any(args, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./sanitization_parameters.json\", \"r\") as f:\n",
    "    window = json.load(f)[\"grams_maximal_window\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Before dropping rows not around 100g nan mean is 0.5577830188679245 and shape is (689, 80)'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Before dropping rows not around 100g nan mean is {mean} and shape is {shape}\".format(\n",
    "    mean = np.mean(pd.isna(mpt.values)),\n",
    "    shape = mpt.shape\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = np.sum(mpt[grams], axis=1)\n",
    "around_100g = mpt.iloc[_and(sums<100+window, sums>100-window)].copy()\n",
    "around_100g[to_normalize] = around_100g[to_normalize].divide(np.sum(around_100g[grams], axis=1), axis=\"index\")*100\n",
    "mpt = around_100g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'After dropping rows not around 100g nan mean is 0.5534805389221557 and shape is (668, 80)'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"After dropping rows not around 100g nan mean is {mean} and shape is {shape}\".format(\n",
    "    mean = np.mean(pd.isna(around_100g.values)),\n",
    "    shape = around_100g.shape\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpt.to_csv(\"../csv/my_personal_trainer.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
